{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECE449: Individaul Project\n",
    "Jie Wang\n",
    "\n",
    "Nov. 11, 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Description\n",
    "\n",
    "In this project, you need to solve an image classification task using coil-20-proc dataset.\n",
    "\n",
    "This dataset consists of 1,440 grayscale images of 20 objects (72 images per object). \n",
    "- Half of each category is for training and half for testing. (e.g. 36 images for training and another 36 images for testing).\n",
    "\n",
    "Through this project, you can learn how to customize dataset loading, design deep models, and train and test models. \n",
    "\n",
    "This is an individual project, so avoid copying others' code. Additionally, you need to print the accuracy results during the training process. \n",
    "\n",
    "> You should use a Python Jupyter Notebook to write down the process and accuracy results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The COIL-20 (Columbia Object Image Library) dataset\n",
    "a collection of grayscale images of 20 different objects. \n",
    "\n",
    "- The \"proc\" in \"COIL-20-proc\" indicates that the images in this dataset have been preprocessed. photographed on a motorized turntable against a black background to provide a 360-degree view. The objects are varied, including toys, household items, and office supplies, to provide a range of shapes and complexities.\n",
    "\n",
    "\n",
    "The preprocessing typically involves normalizing the images in terms of scale and orientation, and the background is often removed to isolate the object of interest. This makes the dataset particularly useful for computer vision tasks like object recognition and classification, where consistency in the input data can significantly improve the performance of machine learning models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Complete the custom dataset, and dataloader.\n",
    "Fill in the code to complete the custom dataset and dataloader, you can refer to https://pytorch.org/tutorials/beginner/basics/data_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import glob\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "class COIL20Dataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.images[index])\n",
    "        label = self.labels[index]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "\n",
    "# Example transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# the COIL-20 images are stored in a directory as below:\n",
    "# - coil-20-proc/\n",
    "#       - 01/obj1__0.png, obj1__1.png, ...\n",
    "#       - 02/...\n",
    "#       - ...\n",
    "#       - 20/....\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_coil20_dataset(base_directory, transform, test_split=0.2):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    \n",
    "    # Iterate over each category directory to collect image paths and labels\n",
    "    for category in range(1, 21):  # Assuming 20 categories\n",
    "        directory = f\"{base_directory}/{str(category).zfill(2)}\"\n",
    "        category_image_paths = glob.glob(f\"{directory}/*.png\")\n",
    "        # print(category_image_paths)\n",
    "        category_labels = [category] * len(category_image_paths)  # Labels are the category number\n",
    "        # print(category_labels)\n",
    "        \n",
    "        image_paths.extend(category_image_paths)\n",
    "        labels.extend(category_labels)\n",
    "    \n",
    "    # Split the dataset into train and test\n",
    "    split_idx = int(len(image_paths) * (1 - test_split))\n",
    "    train_paths, test_paths = image_paths[:split_idx], image_paths[split_idx:]\n",
    "    train_labels, test_labels = labels[:split_idx], labels[split_idx:]\n",
    "    \n",
    "    # Creating the dataset objects\n",
    "    train_dataset = COIL20Dataset(train_paths, train_labels, transform)\n",
    "    test_dataset = COIL20Dataset(test_paths, test_labels, transform)\n",
    "    \n",
    "    # Creating the dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "    \n",
    "    return train_loader, test_loader, train_dataset, test_dataset\n",
    "\n",
    "# Example transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Assuming the base directory is 'coil-20-proc' containing subdirectories '01', '02', ..., '20'\n",
    "train_loader, test_loader, train_dataset, test_dataset = load_coil20_dataset('coil-20-proc', transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x21b8bd746a0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x21b8bd740d0>,\n",
       " <__main__.COIL20Dataset at 0x21b8ad6ee50>,\n",
       " <__main__.COIL20Dataset at 0x21b8ae83250>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader, test_loader, train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1152\n",
      "288\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.__len__() ) \n",
    "print(test_dataset.__len__() ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\# Courses\\## 大四\\FA23\\ECE449_MP\\Individual_Proj\\individual project.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%23%20Courses/%23%23%20%E5%A4%A7%E5%9B%9B/FA23/ECE449_MP/Individual_Proj/individual%20project.ipynb#X22sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mLabels:\u001b[39m\u001b[39m'\u001b[39m, labels\u001b[39m.\u001b[39mnumpy())\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%23%20Courses/%23%23%20%E5%A4%A7%E5%9B%9B/FA23/ECE449_MP/Individual_Proj/individual%20project.ipynb#X22sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# Example usage with your train_loader\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/%23%20Courses/%23%23%20%E5%A4%A7%E5%9B%9B/FA23/ECE449_MP/Individual_Proj/individual%20project.ipynb#X22sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m show_images_from_dataloader(train_loader)\n",
      "\u001b[1;32md:\\# Courses\\## 大四\\FA23\\ECE449_MP\\Individual_Proj\\individual project.ipynb Cell 7\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/%23%20Courses/%23%23%20%E5%A4%A7%E5%9B%9B/FA23/ECE449_MP/Individual_Proj/individual%20project.ipynb#X22sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mshow_images_from_dataloader\u001b[39m(dataloader):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/%23%20Courses/%23%23%20%E5%A4%A7%E5%9B%9B/FA23/ECE449_MP/Individual_Proj/individual%20project.ipynb#X22sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m# Get a batch of training data\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/%23%20Courses/%23%23%20%E5%A4%A7%E5%9B%9B/FA23/ECE449_MP/Individual_Proj/individual%20project.ipynb#X22sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     images, labels \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39miter\u001b[39;49m(dataloader))\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/%23%20Courses/%23%23%20%E5%A4%A7%E5%9B%9B/FA23/ECE449_MP/Individual_Proj/individual%20project.ipynb#X22sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39m# Make a grid from batch\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/%23%20Courses/%23%23%20%E5%A4%A7%E5%9B%9B/FA23/ECE449_MP/Individual_Proj/individual%20project.ipynb#X22sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     out \u001b[39m=\u001b[39m torchvision\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mmake_grid(images)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\utils\\data\\dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\utils\\data\\dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\utils\\data\\_utils\\collate.py:264\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    204\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[39m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[39m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[39m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    263\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 264\u001b[0m     \u001b[39mreturn\u001b[39;00m collate(batch, collate_fn_map\u001b[39m=\u001b[39;49mdefault_collate_fn_map)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\utils\\data\\_utils\\collate.py:150\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    146\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    147\u001b[0m             \u001b[39m# The sequence type may not support `__init__(iterable)` (e.g., `range`).\u001b[39;00m\n\u001b[0;32m    148\u001b[0m             \u001b[39mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]\n\u001b[1;32m--> 150\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[39m.\u001b[39mformat(elem_type))\n",
      "\u001b[1;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "\n",
    "def show_images_from_dataloader(dataloader):\n",
    "    # Get a batch of training data\n",
    "    images, labels = next(iter(dataloader))\n",
    "\n",
    "    # Make a grid from batch\n",
    "    out = torchvision.utils.make_grid(images)\n",
    "\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.imshow(out.numpy().transpose((1, 2, 0)))\n",
    "    plt.title('Batch from dataloader')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    # Print labels\n",
    "    print('Labels:', labels.numpy())\n",
    "\n",
    "# Example usage with your train_loader\n",
    "show_images_from_dataloader(train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Implementing a Neural Network\n",
    "Fill in the code to complete the custom model, you can refer to https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Classify_NN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(128*128,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256,20)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "    # you should complete forward function\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Customize some arguments\n",
    "Usually, this function is not used for jupyter notebook, as it violates the nature of interacive design.\n",
    "\n",
    "Still, I set it mannually for the argument input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_config():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    # you should complete arguments\n",
    "    parser.add_argument()\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    args.device = torch.device(args.device)\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Train and Test the model.\n",
    "Fill in the code to complete the training and testing, and print the results and losses. You can refer to https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html and https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class Coil20_model:\n",
    "    def __init__(self,trainset, testset, logger):\n",
    "        self.train_loader = train_loader \n",
    "        self.test_loader = test_loader\n",
    "        # Operate the method\n",
    "        self.Mymodel = Classify_NN()\n",
    "        self.criterion = nn.CrossEntropyLoss()  \n",
    "        self.optimizer = torch.optim.Adam(self.Mymodel.parameters(), lr=0.001)  \n",
    "\n",
    "    def _train(self, dataloader):\n",
    "    # you should complete the training code, optimizer and loss function\n",
    "        train_loss = 0\n",
    "        n_correct = 0\n",
    "        n_train = len(dataloader)\n",
    "\n",
    "        for image,label in dataloader:\n",
    "            pred_label = self.Mymodel(image)\n",
    "            loss   = self.criterion(pred_label,label)\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            train_loss += loss.item * image.size(0)\n",
    "            # n_correct += \n",
    "\n",
    "        return train_loss / n_train, n_correct / n_train\n",
    "\n",
    "    def _test(self, dataloader):\n",
    "        test_loss = 0\n",
    "        n_correct = 0\n",
    "        n_test    = len(dataloader)\n",
    "        with torch.no_grad():\n",
    "            for img, label in dataloader:\n",
    "                pred_label = self.Mymodel(img)\n",
    "                test_loss += self.criterion(pred_label,label).item() * img.size(0)\n",
    "                if(pred_label == label):\n",
    "                    n_correct += 1\n",
    "\n",
    "        return test_loss / n_test, n_correct / n_test\n",
    "    \n",
    "\n",
    "    def _visualize(self, accuracy, val_accuracy):\n",
    "        plt.plot(accuracy, label='accuracy')\n",
    "        plt.plot(val_accuracy, label='val_accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.ylim([0, 1])\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.show()\n",
    "\n",
    "    def eval(self, dataloader):\n",
    "        total_loss = 0.0\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        with torch.no_grad():  # No need to track gradients for evaluation\n",
    "            for batch_idx, (data, target) in enumerate(dataloader):\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                outputs = self.Mymodel(data)\n",
    "                loss = self.criterion(outputs, target)\n",
    "                \n",
    "                # Sum up batch loss\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                # Get the index of the max log-probability (the predicted class label)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_samples += target.size(0)\n",
    "                total_correct += (predicted == target).sum().item()\n",
    "\n",
    "        # Calculate average loss and accuracy\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        accuracy = total_correct / total_samples\n",
    "\n",
    "        return avg_loss, accuracy\n",
    "\n",
    "    def run(self):\n",
    "    # you should complete run function for training and testing the model, and print the results and losses.\n",
    "        train_loss, train_accuracy  = self._train(self.train_loader)\n",
    "        print(f'Epoch {1}: Train Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.2f}')\n",
    "\n",
    "        print(\"finished training\")\n",
    "        test_loss, test_accuracy = self._test(self.test_loader)\n",
    "        print(f'Epoch {1}: Test Loss: {test_loss:.4f}, Accuracy: {test_accuracy:.2f}')\n",
    "\n",
    "        print(\"finished testing\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\# Courses\\## 大四\\FA23\\ECE449_MP\\Individual_Proj\\individual project.ipynb Cell 14\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/%23%20Courses/%23%23%20%E5%A4%A7%E5%9B%9B/FA23/ECE449_MP/Individual_Proj/individual%20project.ipynb#X16sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m train,test \u001b[39m=\u001b[39m load_coil20_dataset(\u001b[39m'\u001b[39m\u001b[39mcoil-20-proc/\u001b[39m\u001b[39m'\u001b[39m,transform)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/%23%20Courses/%23%23%20%E5%A4%A7%E5%9B%9B/FA23/ECE449_MP/Individual_Proj/individual%20project.ipynb#X16sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m ece449_model \u001b[39m=\u001b[39m Coil20_model(train,test ,logger \u001b[39m=\u001b[39m logging\u001b[39m.\u001b[39mgetLogger())  \n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/%23%20Courses/%23%23%20%E5%A4%A7%E5%9B%9B/FA23/ECE449_MP/Individual_Proj/individual%20project.ipynb#X16sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m ece449_model\u001b[39m.\u001b[39;49mrun()\n",
      "\u001b[1;32md:\\# Courses\\## 大四\\FA23\\ECE449_MP\\Individual_Proj\\individual project.ipynb Cell 14\u001b[0m line \u001b[0;36m7\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%23%20Courses/%23%23%20%E5%A4%A7%E5%9B%9B/FA23/ECE449_MP/Individual_Proj/individual%20project.ipynb#X16sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%23%20Courses/%23%23%20%E5%A4%A7%E5%9B%9B/FA23/ECE449_MP/Individual_Proj/individual%20project.ipynb#X16sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m \u001b[39m# you should complete run function for training and testing the model, and print the results and losses.\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/%23%20Courses/%23%23%20%E5%A4%A7%E5%9B%9B/FA23/ECE449_MP/Individual_Proj/individual%20project.ipynb#X16sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m     train_loss, train_accuracy  \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_loader)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%23%20Courses/%23%23%20%E5%A4%A7%E5%9B%9B/FA23/ECE449_MP/Individual_Proj/individual%20project.ipynb#X16sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: Train Loss: \u001b[39m\u001b[39m{\u001b[39;00mtrain_loss\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, Accuracy: \u001b[39m\u001b[39m{\u001b[39;00mtrain_accuracy\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%23%20Courses/%23%23%20%E5%A4%A7%E5%9B%9B/FA23/ECE449_MP/Individual_Proj/individual%20project.ipynb#X16sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mfinished training\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32md:\\# Courses\\## 大四\\FA23\\ECE449_MP\\Individual_Proj\\individual project.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%23%20Courses/%23%23%20%E5%A4%A7%E5%9B%9B/FA23/ECE449_MP/Individual_Proj/individual%20project.ipynb#X16sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m n_correct \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%23%20Courses/%23%23%20%E5%A4%A7%E5%9B%9B/FA23/ECE449_MP/Individual_Proj/individual%20project.ipynb#X16sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m n_train \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(dataloader)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/%23%20Courses/%23%23%20%E5%A4%A7%E5%9B%9B/FA23/ECE449_MP/Individual_Proj/individual%20project.ipynb#X16sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mfor\u001b[39;00m image,label \u001b[39min\u001b[39;00m dataloader:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%23%20Courses/%23%23%20%E5%A4%A7%E5%9B%9B/FA23/ECE449_MP/Individual_Proj/individual%20project.ipynb#X16sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     pred_label \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mMymodel(image)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%23%20Courses/%23%23%20%E5%A4%A7%E5%9B%9B/FA23/ECE449_MP/Individual_Proj/individual%20project.ipynb#X16sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     loss   \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcriterion(pred_label,label)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\utils\\data\\dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\utils\\data\\dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\utils\\data\\_utils\\collate.py:264\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    204\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[39m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[39m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[39m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    263\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 264\u001b[0m     \u001b[39mreturn\u001b[39;00m collate(batch, collate_fn_map\u001b[39m=\u001b[39;49mdefault_collate_fn_map)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\utils\\data\\_utils\\collate.py:150\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    146\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    147\u001b[0m             \u001b[39m# The sequence type may not support `__init__(iterable)` (e.g., `range`).\u001b[39;00m\n\u001b[0;32m    148\u001b[0m             \u001b[39mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]\n\u001b[1;32m--> 150\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[39m.\u001b[39mformat(elem_type))\n",
      "\u001b[1;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    " transforms.Resize((128, 128)),\n",
    " transforms.ToTensor(),\n",
    " ])\n",
    "train,test = load_coil20_dataset('coil-20-proc/',transform)\n",
    "ece449_model = Coil20_model(train,test ,logger = logging.getLogger())  \n",
    "ece449_model.run()  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save the model\n",
    "torch.save(ece449_model.Mymodel.state_dict(), 'coil20_model.pth')\n",
    "\n",
    "# To load the model\n",
    "ece449_model.Mymodel.load_state_dict(torch.load('coil20_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming test_data_loader is a DataLoader for new data\n",
    "predictions = []\n",
    "ece449_model.Mymodel.eval()  # Set model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    for data in test_data_loader:\n",
    "        data = data.to(args.device)\n",
    "        output = model.Mymodel(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        predictions.extend(pred.cpu().numpy())\n",
    "\n",
    "# predictions now holds the predicted labels for the test data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
