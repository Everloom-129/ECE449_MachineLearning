{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Description\n",
    "\n",
    "In this project, you need to solve an image classification task using coil-20-proc dataset. This dataset consists of 1,440 grayscale images of 20 objects (72 images per object). Half of each category is for training and half for testing. (e.g. 36 images for training and another 36 images for testing). Through this project, you can learn how to customize dataset loading, design deep models, and train and test models. This is an individual project, so avoid copying others' code. Additionally, you need to print the accuracy results during the training process. You should use a Python Jupyter Notebook to write down the process and accuracy results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The COIL-20 (Columbia Object Image Library) dataset\n",
    "a collection of grayscale images of 20 different objects. The \"proc\" in \"COIL-20-proc\" indicates that the images in this dataset have been preprocessed. Each object has been photographed on a motorized turntable against a black background to provide a 360-degree view. The objects are varied, including toys, household items, and office supplies, to provide a range of shapes and complexities.\n",
    "\n",
    "\n",
    "The preprocessing typically involves normalizing the images in terms of scale and orientation, and the background is often removed to isolate the object of interest. This makes the dataset particularly useful for computer vision tasks like object recognition and classification, where consistency in the input data can significantly improve the performance of machine learning models.\n",
    "\n",
    "The COIL-20 dataset is commonly used in academia for teaching and research in the fields of computer vision and machine learning, as it presents a controlled environment that allows for the evaluation of algorithms and techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Complete the custom dataset, and dataloader.\n",
    "Fill in the code to complete the custom dataset and dataloader, you can refer to https://pytorch.org/tutorials/beginner/basics/data_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "class COIL20Dataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.image_paths = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.images[index])\n",
    "        label = self.labels[index]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "\n",
    "def load_coil20_dataset(directory, transform, test_split=0.2):\n",
    "    # Get all the image file paths\n",
    "    image_paths = glob.glob(f\"{directory}/*.png\") # Assuming the images are in PNG format\n",
    "    labels = [int(path.split('_')[1]) for path in image_paths]  # Extracting labels from file names\n",
    "\n",
    "    # Splitting the dataset into train and test\n",
    "    split_idx = int(len(image_paths) * (1 - test_split))\n",
    "    train_paths, test_paths = image_paths[:split_idx], image_paths[split_idx:]\n",
    "    train_labels, test_labels = labels[:split_idx], labels[split_idx:]\n",
    "\n",
    "    # Creating the dataset objects\n",
    "    train_dataset = COIL20Dataset(train_paths, train_labels, transform)\n",
    "    test_dataset = COIL20Dataset(test_paths, test_labels, transform)\n",
    "\n",
    "    # Creating the dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "\n",
    "# Example transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Example usage\n",
    "# Assuming the COIL-20 images are stored in a directory named 'coil20_dataset'\n",
    "train_loader, test_loader = load_coil20_dataset('coil20_dataset', transform)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Implementing a Neural Network\n",
    "Fill in the code to complete the custom model, you can refer to https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mymodel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "    # you should complete __init__ function\n",
    "\n",
    "    def forward(self, x):\n",
    "    # you should complete forward function\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Customize some arguments\n",
    "Fill in the code to complete the custom arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def get_config():\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # you should complete arguments\n",
    "    parser.add_argument()\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    args.device = torch.device(args.device)\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Train and Test the model.\n",
    "Fill in the code to complete the training and testing, and print the results and losses. You can refer to https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html and https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class MyNet:\n",
    "    def __init__(self, args, logger):\n",
    "        self.args = args\n",
    "\n",
    "        # Operate the method\n",
    "        self.Mymodel = Mymodel()\n",
    "        self.Mymodel.to(args.device)\n",
    "        self._print_args()\n",
    "\n",
    "    def _train(self, dataloader, criterion, optimizer):\n",
    "    # you should complete the training code, optimizer and loss function\n",
    "        \n",
    "        return train_loss / n_train, n_correct / n_train\n",
    "\n",
    "    def _test(self, dataloader, criterion):\n",
    "    # you should complete the testing code\n",
    "\n",
    "        return test_loss / n_test, n_correct / n_test\n",
    "\n",
    "    def run(self):\n",
    "    # you should complete run function for training and testing the model, and print the results and losses.\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    args = get_config()\n",
    "    net = MyNet(args)\n",
    "    net.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
